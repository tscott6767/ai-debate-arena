
# âš”ï¸â€¯AIâ€¯Debateâ€¯Arenaâ€¯â€”â€¯Tribunalâ€¯Editionâ€¯(v2.1)

> **Multiâ€‘model, realâ€‘time AI debate framework**  
> Debate any two models live in your browser with an impartial AIâ€¯Judge and full streaming transcripts.

---

## ğŸš€â€¯Overview

AIâ€¯Debateâ€¯Arena lets any combination of language modelsâ€¯(OpenAI,â€¯Groq,â€¯Mistral,â€¯Anthropicâ€¯Claude,â€¯Ollama,â€¯LMâ€¯Studio,â€¯etc.)â€¯argue topics in real time through a FastAPIâ€¯server while aâ€¯Judgeâ€¯model scores each round.

It now includes:

- ğŸ¯â€¯**Multiâ€‘model adapters** (OpenAI,â€¯Groq,â€¯Mistral,â€¯Anthropic,â€¯Ollama,â€¯LMâ€¯Studio)
- âš–ï¸â€¯**AIâ€¯Judge &â€¯Scoring**
- ğŸ’¬â€¯**WebSocket streaming** with live UI inâ€¯theâ€¯browser
- ğŸ§ â€¯**multi_battle_test.py**â€¯for connectivity testing
- âš™ï¸â€¯**Dynamicâ€¯.envâ€¯configuration**
- ğŸª¶â€¯**UTFâ€‘8â€‘safe adapters**â€¯(no moreâ€¯ASCIIâ€¯errors)
- ğŸ’¾â€¯Automaticâ€¯SQLiteâ€¯loggingâ€¯(`debates.db`)
- ğŸŒâ€¯**FastAPIâ€¯+â€¯HTMLâ€¯frontend** served fromâ€¯`/static/index.html`

---

## ğŸ§©â€¯Projectâ€¯Structure


ai-debate-arena/
â”œâ”€â”€ adapters.py              # Provider adapters (OpenAI/Groq/Mistral/Ollama/etc.)
â”œâ”€â”€ controller.py            # Debate loop + judge integration
â”œâ”€â”€ judge.py                 # AI judge logic
â”œâ”€â”€ logger.py                # SQLite transcript logger
â”œâ”€â”€ main.py                  # FastAPI entrypoint / websocket server
â”œâ”€â”€ schemas.py               # Pydantic models
â”œâ”€â”€ multi_battle_test.py     # Connectivity/self-test script
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html           # Live debate front-end
â”œâ”€â”€ .env.example             # Environment template (safe to commit)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE

---

## âš™ï¸â€¯Installationâ€¯&â€¯Setup

```bash
git clone https://github.com/tscott6767/ai-debate-arena.git
cd ai-debate-arena
python -m venv venv
source venv/bin/activate  # (or .\venv\Scripts\activate on Windows)
pip install -r requirements.txt


ğŸ”§â€¯Environmentâ€¯Variables
Copy the template and fill in your keys:
cp .env.example .env
nano .env

Example .env.example contents:
OPENAI_API_KEY=sk-your_openai_key
GROQ_API_KEY=gsk-your_groq_key
MISTRAL_API_KEY=sk-your_mistral_key
ANTHROPIC_API_KEY=sk-ant_your_claude_key

OLLAMA_HOST=http://<your Ollama IP>:11434
FASTAPI_HOST=0.0.0.0
FASTAPI_PORT=8000
DEBATE_DB_PATH=debates.db
DEBUG_MODE=false

Never commitâ€¯.envâ€¯filesâ€”onlyâ€¯.env.exampleâ€¯stays tracked.

ğŸ§ â€¯Quickâ€¯Start
1ï¸âƒ£â€¯Launchâ€¯theâ€¯server
uvicorn main:app --reload --host 0.0.0.0 --port 8000

Visit http://localhost:8000/static/index.html
2ï¸âƒ£â€¯Runâ€¯aâ€¯localâ€¯connectivityâ€¯test
python multi_battle_test.py

If every provider shows âœ…â€¯Firstâ€¯token, all your API keys and hosts are working.

âš”ï¸â€¯Webâ€¯Interface

Enter your debate topic
Choose models for Sideâ€¯Aâ€¯andâ€¯Sideâ€¯B
Select aâ€¯judgeâ€¯model
Pickâ€¯roundâ€¯count
Clickâ€¯Startâ€¯Debate

Watch tokens stream live.
At the end, the judge provides a verdict, summary, andâ€¯scoring table.

ğŸ’¾â€¯Databaseâ€¯Logging
Each debate session (topicâ€¯+â€¯transcriptâ€¯+â€¯scores) is automatically saved toâ€¯debates.db.
Location configurable viaâ€¯DEBATE_DB_PATHâ€¯inâ€¯.env.

ğŸ§°â€¯Connectivityâ€¯Testâ€¯Details
multi_battle_test.pyâ€¯verifies all API integrations independently.
python multi_battle_test.py

Sample output:
ğŸ” Testing ollama  â†’  llama3:latest
âœ… First token: Hello!

ğŸ” Testing openai  â†’  gpt-4o-mini
âœ… First token: Hi there ğŸ˜Š

If you see 404s, update yourâ€¯OLLAMA_HOSTâ€¯to the correct daemon endpoint
(e.g.â€¯http://<your Ollama IP>:11434/api/chatâ€¯vsâ€¯/api/generate).

ğŸ”’â€¯Bestâ€¯Practices



Do
Donâ€™t




Keep .envâ€¯private
Never commit real APIâ€¯keys


Commit .env.exampleâ€¯only



Use isolated Pythonâ€¯venv



Backup debates.db if needed





ğŸ§®â€¯Troubleshooting



Symptom
Cause
Fix




404â€¯@â€¯/chat
Wrong endpoint
Updateâ€¯OllamaAdapterâ€¯orâ€¯OLLAMA_HOST


Unauthorized / api_key mustâ€¯beâ€¯set
Missing keys
Fillâ€¯.envâ€¯andâ€¯loadâ€¯viaâ€¯load_dotenv()


asciiÂ codecÂ can'tÂ encode
Old adapters version
Replaceâ€¯with UTFâ€‘8â€‘safeâ€¯adapters.py (v2.1)


Connectionâ€¯refusedâ€¯@â€¯11434
Ollama daemon off
Startâ€¯ollamaâ€¯serveâ€¯orâ€¯fixâ€¯LANâ€¯IP




ğŸ§¾â€¯Versionâ€¯Controlâ€¯&â€¯GitHubâ€¯Workflow
Pushâ€¯newâ€¯changes
git add main.py adapters.py multi_battle_test.py README.md static/index.html .env.example
git commit -m "Update core files and environment template"
git push origin main

Tagâ€¯aâ€¯release
git tag -a v2.1 -m "Tribunal Edition stable release"
git push origin v2.1


ğŸ§±â€¯Upcomingâ€¯Features

ğŸ†â€¯Tournamentâ€¯bracketsâ€¯(autoâ€¯playâ€‘offs)
ğŸ‘¥â€¯Audienceâ€¯votingâ€¯UI
ğŸ™ï¸â€¯Voiceâ€¯narrationâ€¯viaâ€¯ElevenLabsâ€¯/â€¯XTTS
ğŸŒâ€¯Publicâ€¯galleryâ€¯ofâ€¯pastâ€¯debates
ğŸ”â€¯Userâ€¯accountsâ€¯+â€¯APIâ€¯keysâ€¯perâ€¯user


ğŸ¤â€¯Contributing
Pull requests are welcome!
For major changes, open an issueâ€¯first to discuss what youâ€™d like to modify.

Fork this repo
Create your feature branch:
git checkout -b feature/amazing-update
Commit and pushâ€¯it
Openâ€¯aâ€¯PR againstâ€¯main


ğŸªªâ€¯License
Released under theâ€¯MITâ€¯License.
Seeâ€¯LICENSEâ€¯forâ€¯details.

â¤ï¸â€¯Acknowledgements
Thanks to the openâ€‘source LLMâ€¯communityâ€¯&â€¯contributors who test, troubleshoot, and push AIâ€¯debates into the big arena.


