# âš”ï¸â€¯AIâ€¯Debateâ€¯Arena â€” Tribunalâ€¯Edition

AIâ€¯Debateâ€¯Arenaâ€¯is a **FastAPIâ€‘based realâ€‘time debate simulator** that lets multipleâ€¯LLMs (viaâ€¯Ollamaâ€¯orâ€¯OpenAIâ€‘compatible APIs) argue any topic in a live browser UI.  
It streams tokens as theyâ€™re generated and concludes each round with an optional **AIâ€¯Judge** scoring panel.

---

## ğŸ§ â€¯Features

- ğŸ’¬â€¯Twoâ€¯(models) debate in real time â€” fully streamed to the browser  
- ğŸ§‘â€âš–ï¸â€¯Thirdâ€¯modelâ€¯actsâ€¯asâ€¯aâ€¯judge with logical & persuasion scores  
- ğŸ”„â€¯Supportsâ€¯Ollamaâ€¯(localâ€¯LLMs),â€¯OpenAI,â€¯Groq,â€¯LMâ€¯Studio,â€¯etc.  
- ğŸ’¾â€¯Transcriptsâ€¯automaticallyâ€¯loggedâ€¯toâ€¯SQLiteâ€¯(`debates.db`)  
- ğŸŒâ€¯Simpleâ€¯browserâ€¯interfaceâ€¯withâ€¯modelâ€¯dropdownâ€¯selection  
- âš™ï¸â€¯Configurableâ€¯viaâ€¯`.env`â€¯environmentâ€¯file  

---

## âš¡ï¸â€¯Quickâ€¯StartÂ (Localâ€¯Ollama)

```bash
# 1. Clone the repo
git clone https://github.com/<youruser>/ai-debate-arena.git
cd ai-debate-arena

# 2. Create & activate a virtual environment
python3 -m venv venv
source venv/bin/activate     # (Windows: venv\Scripts\activate)

# 3. Install dependencies
pip install -r requirements.txt

# 4. Copy the environment template
cp .env.example .env
# (default assumes Ollama runs locally on portâ€¯11434)

# 5. Launch Ollama in another terminal
ollama serve

# 6. Start the debate arena
uvicorn main:app --host 0.0.0.0 --port 8000 --reload

Then open
ğŸ‘‰â€¯http://localhost:8000/static/index.html

ğŸŒâ€¯Usingâ€¯aâ€¯Remoteâ€¯Ollamaâ€¯Server
If your LLMs run on another machine:
1.â€¯Editâ€¯.envâ€¯on the FastAPIâ€¯host:
OLLAMA_HOST=http://<remoteâ€‘ip>:11434
FASTAPI_HOST=0.0.0.0
FASTAPI_PORT=8000

2.â€¯Make sureâ€¯Ollamaâ€¯isâ€¯listeningâ€¯onâ€¯thatâ€¯IPâ€¯andâ€¯firewall allowsâ€¯TCPâ€¯11434.
3.â€¯Restartâ€¯theâ€¯FastAPIâ€¯serverâ€¯â†’â€¯modelsâ€¯fromâ€¯thatâ€¯server will appear automatically.

ğŸ–¥ï¸â€¯UIâ€¯Guide



Section
Purpose




Topic Field
Enter any debate subject


Sideâ€¯A /â€¯Sideâ€¯B /â€¯Judge
Choose models (populated from /api/models)


STARTâ€¯DEBATE
Begins a realâ€‘time exchange between the chosen models


Logâ€¯Window
Streams live tokens and the judgeâ€™s final verdict



All debates are stored inâ€¯debates.dbâ€¯with timestamps.
To view saved logs:
sqlite3 debates.db "SELECT id, ts, topic, length(transcript) FROM debates;"


âš™ï¸â€¯Configuration (.env)
# Edit and rename .env.example â†’ .env
OLLAMA_HOST=http://localhost:11434
FASTAPI_HOST=0.0.0.0
FASTAPI_PORT=8000
DEBATE_DB_PATH=debates.db


ğŸ§­â€¯RESTâ€¯Endpoints



HTTPâ€¯Method
Route
Description




GET
/
Healthâ€‘check / welcomeâ€¯message


GET
/api/models
Returns availableâ€¯Ollamaâ€¯models


WS
/ws/debate
Biâ€‘directionalâ€¯WebSocketâ€¯stream for debates




ğŸ§‘â€ğŸ’»â€¯Developmentâ€¯Tips

Test model connectivity manually:
curl http://<OLLAMA_HOST>/api/tagscurl -X POST http://<OLLAMA_HOST>/api/chat \   -H "Content-Type: application/json" \   -d '{"model":"llama3:latest","messages":[{"role":"user","content":"Hello"}]}'

Restartâ€¯uvicornâ€¯after editingâ€¯.pyâ€¯files (CTRL+Câ€¯â†’â€¯rerun).
Useâ€¯python -m py_compile *.pyâ€¯to validate syntax before committing.


ğŸ›¡ï¸â€¯Securityâ€¯Notes

Never commit your personal .env. Commit only .env.example.
If exposing publicly, proxy throughâ€¯NGINXâ€¯with HTTPSâ€¯(Letâ€™sâ€¯Encrypt)â€¯orâ€¯Cloudflareâ€¯Tunnel.
Useâ€¯Proxmoxâ€¯LXCâ€¯orâ€¯Dockerâ€¯for process isolation.


ğŸ§±â€¯Folderâ€¯Structure
ai-debate-arena/
â”‚
â”œâ”€â”€ adapters.py       # model interfaces (Ollama / OpenAI)
â”œâ”€â”€ controller.py     # debate orchestrator
â”œâ”€â”€ judge.py          # judge logic
â”œâ”€â”€ logger.py         # SQLite logger
â”œâ”€â”€ main.py           # FastAPI entrypoint
â”œâ”€â”€ schemas.py        # Pydantic classes
â”œâ”€â”€ static/           # web UI (index.html + JS)
â”œâ”€â”€ .env.example
â”œâ”€â”€ debates.db
â””â”€â”€ venv/             # virtual environment (local)


ğŸ§ªâ€¯Knownâ€¯Testedâ€¯Setups

âœ…â€¯Ubuntuâ€¯22.04â€¯LXCâ€¯onâ€¯Proxmox
âœ…â€¯Ollamaâ€¯0.1.40â€¯(remote & local)
âœ…â€¯Pythonâ€¯3.10â€¯â†’â€¯3.12
âœ…â€¯FastAPIâ€¯+â€¯Uvicornâ€¯+â€¯httpx


ğŸ“œâ€¯License
MITâ€¯Licenseâ€¯Â©â€¯2025â€¯Antony L Scott
Seeâ€¯LICENSEâ€¯for full text.

â¤ï¸â€¯Contributing
1.â€¯Fork this repo
2.â€¯Create a feature branchâ€¯ â†’â€¯ git checkout -b feature/someâ€‘idea
3.â€¯Commitâ€¯changes
4.â€¯Pushâ€¯and openâ€¯aâ€¯Pullâ€¯Request

###â€¯âœ¨â€¯Example Topics

Should AI be open source?
Can machines ever truly understand consciousness?
Is time an illusion?



"The best way to test an idea is to argue with an equal."
â€”â€¯AIâ€¯Debateâ€¯Arenaâ€¯Team

